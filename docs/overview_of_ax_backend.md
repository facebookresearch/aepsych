---
id: ax_backend_overview
title: Overview of AX backend
---

The structure of the AEPsych API can be seen in the following diagram, where each component corresponds to a Python class:

![AEPsych API](assets/new_api_diagram.png)

- **[AEPsychStrategy](../aepsych/strategy.py#L500)**: The AEPsychStrategy carrys out an experiment with a generation strategy using AxClient object for communicating with the Ax/AEPsych server and a GenerationStrategy object for defining the steps in the experiment. It reads strategies from configuration files and call the AxClient to create experiment. It handles experiment definitions, generation of evaluated new points, adding data for completed trials, checking if the experiment is finished, and plotting the results.

- **[AxClient](https://github.com/facebook/Ax/blob/main/ax/service/ax_client.py#L108)**: The AxClient class serves as a convenience handler for managing experimentation cycles. It acts as a service-like API, where an external system schedules the cycle and makes calls to the client for the next suggestion in the experiment and to log back the evaluation data for that suggestion. The class allows for customization of the generation strategy, database settings, sequential optimization enforcement, random seed, torch device, logging verbosity, and early/global stopping strategies. The AxClient is designed to only propose one arm per trial, with support for batch use cases coming soon. The class is powered by the Union of multiple custom types such as TParamValue and TParameterization for convenience.
    
- **[GenerationStrategy](https://github.com/facebook/Ax/blob/main/ax/modelbridge/generation_strategy.py#L46)**: The GenerationStrategy class describes the strategy for selecting a model to generate new points for trials in an optimization process. The strategy is defined by a list of GenerationStep objects, which describes which model to use and the number of trials to generate using that model. The strategy can also be given a name, and the name is generated by default by concatenating the names of the models used in the steps. The class has properties and methods to track the current step in the strategy, the model transitions between steps, and the model currently in use. Additionally, it provides logging and error handling for invalid input.
   
- **[Experiment](https://github.com/facebook/Ax/blob/main/ax/core/experiment.py#L59)**: An Experiment defines the entire set of parameter objects, and parameter constraints of the parameter space. The experiments configurations define the search space for the experiment, including the parameters and their bounds, and the definition of the objective or objectives to optimize. Additionally, constraints on the outcomes can be specified, as well as various other settings such as the type of the experiment and tracking metrics. 
     
- **[AxSobolGenerator](../aepsych/generators/sobol_generator.py#L93)**: AxSobolGenerator is a generation step class that generates points using SobolGenerator. This Generator generates quasi-random low discrepancy experimentation points for the parameter space.
    
- **[AxOptimizeAcqfGenerator](../aepsych/generators/optimize_acqf_generator.py#L182)**: The AxOptimizeAcqfGenerator generates acquisition functions in the context of model-based optimization. It is a wrapper for Ax's BOTORCH_MODULAR, consisting of two main components, the AEPsychSurrogate and the AEPsychAcquisitionFunction. It aims to abstract away the interfaces between AEPsych, Ax and Botorch. 
    
- **[AEPsychSurrogate](../aepsych/models/surrogate.py#L18)**: It is a wrapper for the machine learning model used to make predictions about outcomes based on input data. It uses the collected data to compute the response probabilities at any point in the parameter space. This is wrapper arround BoTorch's Model class, it determines what model, its options, its max_fit_time, and its model class. 

- **[AEPsychAcquisition](../aepsych/acquisition/acquisition.py#L15)**: Acquisition functions use the strategy's model to determine which points should be sampled next, with some overarching goal in mind. We recommend PairwiseMCPosteriorVariance for global exploration, and qNoisyExpectedImprovement for optimization. For other options, check out the botorch and aepsych docs. The class also subsets the model to include only the outcomes needed for optimization. If multiple objectives are present, the class will also infer the objective thresholds using the model.

You may implement an AEPsych experiment using these classes directly in Python, but users who are not familiar with Python can also configure an AEPsych server using a config file.
