{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ff418a0",
   "metadata": {},
   "source": [
    "# Ordinal probit models\n",
    "\n",
    "This note briefly reviews ordinal models from a psychohysics perspective. For more on Ordinal GP, see https://www.jmlr.org/papers/volume6/chu05a/chu05a.pdf. \n",
    "\n",
    "In standard psychophysics theory, we have two stimuli, $x_1$ and $x_2$, and we assume the latent representations of both are corrupted by noise to yield latent percepts: \n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\widetilde{f}(x_1) &= f(x_1) + \\epsilon_1, \\epsilon_1 \\sim \\mathcal{N}(0, \\sigma)\\\\\n",
    "\\widetilde{f}(x_2) &= f(x_2) + \\epsilon_2, \\epsilon_2 \\sim \\mathcal{N}(0, \\sigma),\n",
    "\\end{aligned}\n",
    "$$\n",
    "where under Weber's law we expect $f(x)$ to be the log function but in AEPsych we assume it is more general. For symmetric noise distributions, this is equivalent to saying $f(x_n) = \\widetilde{f}(x_n) + \\epsilon_n$, which is equivalent to the following model: \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "f(x_1) &\\sim \\mathcal{N}(\\widetilde{f}(x_1), \\sigma^2)\\\\\n",
    "f(x_2) &\\sim \\mathcal{N}(\\widetilde{f}(x_2), \\sigma^2). \n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Then when we ask the participant to respond based on which stimulus is stronger, we ask them to respond yes if $f(x_1)>f(x_2)$ and respond no otherwise. By definition, \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "p(f(x_1) > f(x_2)) &=p(f(x_1) - f(x_2) > 0)\\\\\n",
    "&= \\Phi(f(x_1)-f(x_2)), \n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "which is the standard pairwise model available in AEPsych. We can ask the participant to change their response criteria, which would imply a model like $p(f(x_1) > f(x_2)) =p(f(x_1) - f(x_2) > d)$ for criterion $d$. In detection experiments, we treat $f(x_2)$ as a constant, and for an $f(\\cdot)$ that can model shifts it can just be zero, yielding $z(x\\mid f) = \\Phi(f(x))$, which is the standard single model available in AEPsych. \n",
    "\n",
    "However, we can extend this ideaa to a larger number of ratings. Suppose that: \n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\widetilde{f}(x_1) &= f(x_1) + \\epsilon_1, \\epsilon_1 \\sim \\mathcal{N}(0, \\sigma^2)\\\\\n",
    "\\ldots\\\\\n",
    "\\widetilde{f}(x_n) &= f(x_n) + \\epsilon_n, \\epsilon_n \\sim \\mathcal{N}(0, \\sigma^2),\n",
    "\\end{aligned}\n",
    "$$\n",
    "for $n$ stimuli, and equivalently $f(x) \\sim \\mathcal{N}(\\widetilde{f}(x), \\sigma^2)$ (i.e.\\ it's the same exact model). Then we ask the participant to make one of $n$ responses corresponding to the strength of the stimulus (for example \"no stimulus\", \"weak stimulus\", \"moderate stimulus\", \"strong stimulus\", \"very strong stimulus\" for a 5-point scale). We assume that the participant has a set of internal criteria $\\{d_1, \\cdots, d_{k+1}\\}$ subdividing their internal perceptual intensity space into $k$ regions. Assuming each region in the space must be assigned to some response, we set $d_1=-\\infty$ and $d_{k+1} = \\infty$. Then the probability that a participant picks a rating is the probability that the noisy internal percept falls into the appropriate bucket, i.e. $p(y=k\\mid x) = p(d_k < f(x) \\le d_{k+1})$. This is simply the proportion of $f(x)$ that falls between $d_k$ and $d_{k+1}$, i.e.\\ it is the difference between the CDF of $f(x)$ evaluated at $d_{k+1}$ and $d_k$: \n",
    "$$\n",
    "z_k(x\\mid f) := p(d_k < f(x) \\le d_{k+1}) = \\Phi(d_{k+1}-f(x)) - \\Phi(d_{k}-f(x)). \n",
    "$$\n",
    "Supposing that we want the marginal response probability (integrating over the uncertainty in the GP), due to the linearity of expectation it is: \n",
    "$$\n",
    "z_k(x) = \\Phi\\left(\\frac{d_{k+1}-\\mu(x)}{\\sqrt{1+\\sigma(x)^2}}\\right) - \\Phi\\left(\\frac{d_{k}-\\mu(x)}{\\sqrt{1+\\sigma(x)^2}}\\right), \n",
    "$$\n",
    "\n",
    "Next we show how to generate and fit such data in AEPsych.  **Note that this should be considered alpha-level functionality that has not yet had the level of polish or testing as other models in AEPsych. However, we hope it proves useful.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96beb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports and seeds\n",
    "import gpytorch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from aepsych.benchmark.test_functions import novel_detection_testfun\n",
    "from aepsych.utils import dim_grid, make_scaled_sobol\n",
    "from scipy.stats import norm\n",
    "from torch.distributions import Categorical, Normal\n",
    "\n",
    "\n",
    "np.random.seed(1)\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35d67a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hairtie test function\n",
    "lb = [-1, -1]\n",
    "ub = [1, 1]\n",
    "\n",
    "xgrid = dim_grid(lower=lb, upper=ub, dim=2)\n",
    "\n",
    "fgrid = novel_detection_testfun(xgrid)\n",
    "\n",
    "plt.imshow(fgrid.reshape(30, 30).T, aspect=\"auto\", origin=\"lower\")\n",
    "plt.colorbar()\n",
    "plt.title(\"Latent function f(x)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075a4684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, pick the number of levels and make using evenly spaced cutpoints over the distribution of function values\n",
    "n_levels = 5\n",
    "cutpoints = np.quantile(fgrid, np.linspace(0.05, 0.95, n_levels - 1))\n",
    "\n",
    "\n",
    "def make_prob_matrix(fgrid, cutpoints, n_levels):\n",
    "    \"\"\"\n",
    "    Generates the matrix of response probabilities for each choice given function values, cutpoints, \n",
    "    and number of levels.\n",
    "    \"\"\"\n",
    "    probs = np.zeros((*fgrid.shape, n_levels))\n",
    "\n",
    "    probs[..., 0] = norm.cdf(cutpoints[0] - fgrid)\n",
    "\n",
    "    for i in range(1, n_levels - 1):\n",
    "        probs[..., i] = norm.cdf(cutpoints[i] - fgrid) - norm.cdf(cutpoints[i - 1] - fgrid)\n",
    "\n",
    "    probs[..., -1] = 1 - norm.cdf(cutpoints[-1] - fgrid)\n",
    "    return probs\n",
    "\n",
    "\n",
    "probs_grid = make_prob_matrix(fgrid, cutpoints, n_levels)\n",
    "\n",
    "# now see what the probabilities of each rating look like\n",
    "for i in range(n_levels):\n",
    "    plt.figure()\n",
    "    plt.imshow(probs_grid[..., i].reshape(30, 30).T, aspect=\"auto\", origin=\"lower\")\n",
    "    plt.title(f\"rating={i}\")\n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ecf2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now generate some data from the categorical distribution defined over a set of training locations\n",
    "xtrain = make_scaled_sobol(lb=lb, ub=ub, size=50)\n",
    "ftrain = novel_detection_testfun(xtrain)\n",
    "train_probs = make_prob_matrix(ftrain, cutpoints=cutpoints, n_levels=n_levels)\n",
    "ytrain = Categorical(probs=torch.Tensor(train_probs)).sample(torch.Size([1])).squeeze()\n",
    "\n",
    "for i in range(n_levels):\n",
    "    plt.plot(xtrain[ytrain == i, 0], xtrain[ytrain == i, 1], \"o\", label=i)\n",
    "    plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edcb796",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aepsych.models import OrdinalGPModel\n",
    "from aepsych.likelihoods import OrdinalLikelihood\n",
    "\n",
    "# OrdinalGPModel is a thin wrapper around the regular GPClassificationModel, but removes the shift and scale, since those are invariant for the ordinal model, \n",
    "# and adds a convenience method for predicting response probabilities\n",
    "\n",
    "model = OrdinalGPModel(lb=lb, ub=ub, dim=2, likelihood=OrdinalLikelihood(n_levels=n_levels))\n",
    "model.fit(xtrain, ytrain, warmstart_hyperparams=True, warmstart_induc=True)\n",
    "\n",
    "# generate predicted response probabilities and plot, showing we recover a function that looks broadly close to the original\n",
    "probs_hat = model.predict_probs(xgrid).detach().numpy()\n",
    "for i in range(n_levels):\n",
    "    plt.figure()\n",
    "    plt.imshow(probs_hat[..., i].reshape(30, 30).T, aspect=\"auto\", origin=\"lower\")\n",
    "    plt.title(f\"rating={i}\")\n",
    "    plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd0d5ac",
   "metadata": {},
   "source": [
    "# Ordinal Probit models in a full experiment loop\n",
    "Ordinal models can be used with any acquisition function, but AEPsych today does not have ones that have been specifically validated for this setting, so in this example we just use sobol: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93527b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash --bg\n",
    "\n",
    "aepsych_server --ip 0.0.0.0 --port 5555 database --db likert_example.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40b99c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aepsych_client import AEPsychClient\n",
    "client = AEPsychClient(ip=\"0.0.0.0\", port=5555)\n",
    "\n",
    "# this is just configs/likert_exploration_example.ini\n",
    "config_str = \"\"\"\n",
    "### Example config for ordinal (likert) data\n",
    "# Assuming you are learning a latent value from k-point scores,  the\n",
    "# only things that need to be changed for a\n",
    "# typical experiment are:\n",
    "# 1. parnames, lb and ub under [common], and optionally target.\n",
    "# 2. min_asks under init_strat\n",
    "# 3. n_levels under OrdinalLikelihood\n",
    "\n",
    "## The common section includes global server parameters and parameters\n",
    "## reused in multiple other classes\n",
    "[common]\n",
    "parnames = [par1, par2] # names of the parameters\n",
    "lb = [-1, -1] # lower bounds of the parameters, in the same order as above\n",
    "ub = [1, 1] # upper bounds of parameter, in the same order as above\n",
    "stimuli_per_trial = 1 # the number of stimuli shown in each trial; 1 for single, or 2 for pairwise experiments\n",
    "outcome_types = [ordinal] \n",
    "strategy_names = [init_strat] # The strategies that will be used, corresponding to the named sections below\n",
    "\n",
    "# Configuration for the initialization strategy, which we use to gather initial points\n",
    "# before we start doing model-based acquisition\n",
    "[init_strat]\n",
    "min_asks = 50 # number of sobol trials to run\n",
    "generator = SobolGenerator # The generator class used to generate new parameter values\n",
    "model = OrdinalGPModel\n",
    "refit_every = 50\n",
    "\n",
    "## Below this section are configurations of all the classes defined in the section above,\n",
    "## matching the API in the code.\n",
    "\n",
    "## OrdinalGPModel model settings.\n",
    "[OrdinalGPModel]\n",
    "# Number of inducing points for approximate inference. 100 is fine for 2d and overkill for 1d;\n",
    "# for larger dimensions, scale this up.\n",
    "inducing_size = 100\n",
    "# ordinal_mean_covar_factory has better defaults for the ordinal setting than the default factory, \n",
    "mean_covar_factory = ordinal_mean_covar_factory\n",
    "likelihood = OrdinalLikelihood\n",
    "\n",
    "[OrdinalLikelihood]\n",
    "n_levels = 5\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd54d496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure AEPsych to run this experiment\n",
    "client.configure(config_str=config_str, config_name=\"likert_sobol_2d\")\n",
    "\n",
    "def simulate_trial(trial_config):\n",
    "    \"\"\"\n",
    "    Generate synthetic responses from our model (defined above)\n",
    "    \"\"\"\n",
    "    x = torch.Tensor(np.r_[trial_config['config']['par1'][0], trial_config['config']['par2'][0]])\n",
    "    p = make_prob_matrix(novel_detection_testfun(x), cutpoints=cutpoints, n_levels=n_levels)\n",
    "    return Categorical(probs=torch.Tensor(p)).sample(torch.Size([1])).squeeze().item()\n",
    "\n",
    "\n",
    "# run a full synthetic experiment loop\n",
    "finished = False\n",
    "trial_number = 1\n",
    "while not finished:\n",
    "    trial_config = client.ask()\n",
    "    outcome = simulate_trial(trial_config=trial_config)\n",
    "    client.tell(config=trial_config['config'], outcome=outcome)\n",
    "    finished = trial_config[\"is_finished\"]\n",
    "    trial_number += 1\n",
    "\n",
    "client.finalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660de43b",
   "metadata": {},
   "source": [
    "# Replaying the experiment and analyzing data\n",
    "\n",
    "This section is nearly identical to the analysis in the basic analysis tutorial, but we can add some likert-specific plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf1ed37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aepsych.server import AEPsychServer\n",
    "\n",
    "serv = AEPsychServer(database_path=\"likert_example.db\")\n",
    "strat = serv.get_strat_from_replay()\n",
    "strat.fit() # make sure the model is fully updated with latest data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378631ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can look at the data\n",
    "print(strat.x)\n",
    "print(strat.y)\n",
    "for i in range(strat.model.likelihood.n_levels):\n",
    "    plt.plot(strat.x[strat.y == i, 0], strat.x[strat.y == i, 1], \"o\", label=i)\n",
    "    plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fbe51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can generate the same plots as from when we fit the model above: \n",
    "probs_hat = strat.model.predict_probs(xgrid).detach().numpy()\n",
    "for i in range(n_levels):\n",
    "    plt.figure()\n",
    "    plt.imshow(probs_hat[..., i].reshape(30, 30).T, aspect=\"auto\", origin=\"lower\")\n",
    "    plt.title(f\"rating={i}\")\n",
    "    plt.colorbar()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aepsych",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "d5cd175c0c40f7502ca75fb5854cb93650fb8eb5d6fa501b3a333595e244f6e7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
