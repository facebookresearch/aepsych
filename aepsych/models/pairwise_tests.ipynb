{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pairwise_probit import PairwiseGP\n",
    "import torch\n",
    "from variational_gp import BinaryClassificationGP\n",
    "from aepsych.config import Config\n",
    "from gpytorch.likelihoods import BernoulliLikelihood\n",
    "from botorch.models.likelihoods.pairwise import PairwiseProbitLikelihood, PairwiseLikelihood\n",
    "from aepsych.models.base import AEPsychModel\n",
    "from aepsych.models.surrogate import AEPsychSurrogate\n",
    "from aepsych.models.pairwise_probit import PairwiseProbitModel\n",
    "from sklearn.datasets import make_classification\n",
    "from aepsych.utils import promote_0d, _process_bounds\n",
    "from scipy.stats import norm\n",
    "\n",
    "import time\n",
    "from typing import Any, Dict, Optional\n",
    "from aepsych.config import Config\n",
    "from aepsych.utils_logging import getLogger\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from botorch.models import PairwiseGP, PairwiseLaplaceMarginalLogLikelihood\n",
    "from botorch.models.transforms.input import Normalize\n",
    "logger = getLogger()\n",
    "\n",
    "class PairwiseGPModel(PairwiseGP, AEPsychModel, AEPsychSurrogate):\n",
    "    name = \"PairwiseProbitModel\"\n",
    "    outcome_type = \"binary\"\n",
    "    stimuli_per_trial = 1\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        config: Config,\n",
    "        datapoints: Optional[torch.Tensor] = None,\n",
    "        comparisons: Optional[torch.Tensor] = None,\n",
    "    ):\n",
    "        config_opts = self.get_config_options(config)\n",
    "        lb = config.getlist(\"common\", \"lb\", element_type=float)\n",
    "        ub = config.getlist(\"common\", \"ub\", element_type=float)\n",
    "        self.lb, self.ub, dim = _process_bounds(lb, ub, None)\n",
    "\n",
    "        \n",
    "        bounds = torch.stack((self.lb, self.ub))\n",
    "        input_transform = Normalize(d=dim, bounds=bounds)\n",
    "\n",
    "        super().__init__(\n",
    "            datapoints=datapoints,\n",
    "            comparisons=comparisons,\n",
    "            covar_module=config_opts[\"covar_module\"],\n",
    "            jitter=1e-3,\n",
    "            input_transform=input_transform,\n",
    "        )\n",
    "\n",
    "        self.dim = dim  # The Pairwise constructor sets self.dim = None.\n",
    "            \n",
    "\n",
    "    @classmethod\n",
    "    def get_mll_class(cls):\n",
    "        return PairwiseLaplaceMarginalLogLikelihood\n",
    "    \n",
    "    def predict(\n",
    "        self, x, probability_space=False, num_samples=1000, rereference=\"x_min\"\n",
    "    ):\n",
    "        if rereference is not None:\n",
    "            samps = self.sample(x, num_samples, rereference)\n",
    "            fmean, fvar = samps.mean(0).squeeze(), samps.var(0).squeeze()\n",
    "        else:\n",
    "            post = self.posterior(x)\n",
    "            fmean, fvar = post.mean.squeeze(), post.variance.squeeze()\n",
    "\n",
    "        if probability_space:\n",
    "            return (\n",
    "                promote_0d(norm.cdf(fmean)),\n",
    "                promote_0d(norm.cdf(fvar)),\n",
    "            )\n",
    "        else:\n",
    "            return fmean, fvar\n",
    "    \n",
    "    def fit(\n",
    "        self,\n",
    "        train_x: torch.Tensor,\n",
    "        train_y: torch.Tensor,\n",
    "        optimizer_kwargs: Optional[Dict[str, Any]] = None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.train()\n",
    "        mll = PairwiseLaplaceMarginalLogLikelihood(self.likelihood, self)\n",
    "        datapoints, comparisons = PairwiseProbitModel._pairs_to_comparisons(train_x, train_y)\n",
    "        self.set_train_data(datapoints, comparisons)\n",
    "\n",
    "        optimizer_kwargs = {} if optimizer_kwargs is None else optimizer_kwargs.copy()\n",
    "        max_fit_time = kwargs.pop(\"max_fit_time\", self.max_fit_time)\n",
    "        if max_fit_time is not None:\n",
    "            # figure out how long evaluating a single samp\n",
    "            starttime = time.time()\n",
    "            _ = mll(self(datapoints), comparisons)\n",
    "            single_eval_time = time.time() - starttime\n",
    "            n_eval = int(max_fit_time / single_eval_time)\n",
    "            optimizer_kwargs[\"maxfun\"] = n_eval\n",
    "            logger.info(f\"fit maxfun is {n_eval}\")\n",
    "\n",
    "        logger.info(\"Starting fit...\")\n",
    "        starttime = time.time()\n",
    "        fit_gpytorch_mll(mll, **kwargs, **optimizer_kwargs)\n",
    "        logger.info(f\"Fit done, time={time.time()-starttime}\")\n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def get_config_options(cls, config: Config, name: str = None):\n",
    "        options = super().get_config_options(config, name)\n",
    "        classname = cls.__class__.__name__\n",
    "\n",
    "        inducing_point_method = config.get(\n",
    "            classname, \"inducing_point_method\", fallback=\"auto\"\n",
    "        )\n",
    "        inducing_size = config.getint(classname, \"inducing_size\", fallback=10)\n",
    "        learn_inducing_points = config.getboolean(\n",
    "            classname, \"learn_inducing_points\", fallback=False\n",
    "        )\n",
    "\n",
    "        options.update(\n",
    "            {\n",
    "                \"inducing_size\": inducing_size,\n",
    "                \"inducing_point_method\": inducing_point_method,\n",
    "                \"learn_inducing_points\": learn_inducing_points,\n",
    "                \"likelihood\" : PairwiseProbitLikelihood()\n",
    "            }\n",
    "        )\n",
    "\n",
    "        return options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalize()\n",
      "{'likelihood': PairwiseProbitLikelihood(), 'covar_module': ScaleKernel(\n",
      "  (base_kernel): RBFKernel(\n",
      "    (lengthscale_prior): GammaPrior()\n",
      "    (raw_lengthscale_constraint): GreaterThan(1.000E-04)\n",
      "  )\n",
      "  (outputscale_prior): SmoothedBoxPrior()\n",
      "  (raw_outputscale_constraint): Positive()\n",
      "), 'mean_module': ConstantMean(), 'max_fit_time': None, 'inducing_size': 10, 'inducing_point_method': 'auto', 'learn_inducing_points': False}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'lb': tensor([0., 0.], dtype=torch.float32),\n",
       " 'ub': tensor([1., 1.], dtype=torch.float32),\n",
       " 'training': True,\n",
       " '_parameters': OrderedDict(),\n",
       " '_buffers': OrderedDict([('datapoints', None),\n",
       "              ('comparisons', None),\n",
       "              ('D', None),\n",
       "              ('DT', None),\n",
       "              ('utility', None),\n",
       "              ('covar_chol', None),\n",
       "              ('likelihood_hess', None),\n",
       "              ('hlcov_eye', None),\n",
       "              ('covar', None),\n",
       "              ('covar_inv', None)]),\n",
       " '_non_persistent_buffers_set': set(),\n",
       " '_backward_hooks': OrderedDict(),\n",
       " '_is_full_backward_hook': None,\n",
       " '_forward_hooks': OrderedDict(),\n",
       " '_forward_pre_hooks': OrderedDict(),\n",
       " '_state_dict_hooks': OrderedDict(),\n",
       " '_load_state_dict_pre_hooks': OrderedDict([(29,\n",
       "               <torch.nn.modules.module._WrappedHook at 0x1fee0e333d0>)]),\n",
       " '_load_state_dict_post_hooks': OrderedDict(),\n",
       " '_modules': OrderedDict([('likelihood', PairwiseProbitLikelihood()),\n",
       "              ('mean_module', ConstantMean()),\n",
       "              ('covar_module',\n",
       "               ScaleKernel(\n",
       "                 (base_kernel): RBFKernel(\n",
       "                   (lengthscale_prior): GammaPrior()\n",
       "                   (raw_lengthscale_constraint): GreaterThan(1.000E-04)\n",
       "                 )\n",
       "                 (outputscale_prior): SmoothedBoxPrior()\n",
       "                 (raw_outputscale_constraint): Positive()\n",
       "               ))]),\n",
       " '_added_loss_terms': OrderedDict(),\n",
       " '_priors': OrderedDict(),\n",
       " '_constraints': OrderedDict(),\n",
       " '_strict_init': True,\n",
       " '_load_strict_shapes': True,\n",
       " 'train_inputs': [],\n",
       " 'train_targets': None,\n",
       " 'pred_cov_fac_need_update': True,\n",
       " 'dim': 2,\n",
       " '_jitter': 0.001,\n",
       " '_xtol': None,\n",
       " '_maxfev': None,\n",
       " '_x0': None}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X, y = make_classification(\n",
    "            n_samples=10,\n",
    "            n_features=1,\n",
    "            n_redundant=0,\n",
    "            n_informative=1,\n",
    "            random_state=1,\n",
    "            n_clusters_per_class=1,\n",
    "        )\n",
    "X, y = torch.Tensor(X), torch.Tensor(y)\n",
    "\n",
    "datapoints = torch.Tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "comparisons = torch.Tensor([[0, 1], [2, 1]])\n",
    "\n",
    "\n",
    "config_file = \"../../configs/ax_pairwise_opt_example.ini\"\n",
    "config = Config(config_fnames=[config_file])\n",
    "pairwise_model = PairwiseGPModel(config, datapoints= datapoints)\n",
    "\n",
    "config_opts = pairwise_model.get_config_options(config)\n",
    "print(config_opts)\n",
    "vars(pairwise_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ckamd\\anaconda3\\envs\\aepsych\\lib\\site-packages\\botorch\\models\\utils\\assorted.py:173: InputDataWarning:\n",
      "\n",
      "Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "\n",
      "c:\\Users\\ckamd\\anaconda3\\envs\\aepsych\\lib\\site-packages\\botorch\\models\\utils\\assorted.py:201: InputDataWarning:\n",
      "\n",
      "Input data is not standardized. Please consider scaling the input to zero mean and unit variance.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'_num_outputs': 1,\n",
       " '_input_batch_shape': torch.Size([]),\n",
       " '_aug_batch_shape': torch.Size([]),\n",
       " '_is_custom_likelihood': True,\n",
       " '_inducing_point_allocator': <botorch.models.utils.inducing_point_allocators.GreedyVarianceReduction at 0x1fee0e2f280>,\n",
       " 'training': True,\n",
       " '_parameters': OrderedDict(),\n",
       " '_buffers': OrderedDict(),\n",
       " '_non_persistent_buffers_set': set(),\n",
       " '_backward_hooks': OrderedDict(),\n",
       " '_is_full_backward_hook': None,\n",
       " '_forward_hooks': OrderedDict(),\n",
       " '_forward_pre_hooks': OrderedDict(),\n",
       " '_state_dict_hooks': OrderedDict(),\n",
       " '_load_state_dict_pre_hooks': OrderedDict(),\n",
       " '_load_state_dict_post_hooks': OrderedDict(),\n",
       " '_modules': OrderedDict([('model',\n",
       "               _SingleTaskVariationalGP(\n",
       "                 (variational_strategy): VariationalStrategy(\n",
       "                   (_variational_distribution): CholeskyVariationalDistribution()\n",
       "                 )\n",
       "                 (mean_module): ConstantMean()\n",
       "                 (covar_module): ScaleKernel(\n",
       "                   (base_kernel): MaternKernel(\n",
       "                     (lengthscale_prior): GammaPrior()\n",
       "                     (raw_lengthscale_constraint): Positive()\n",
       "                   )\n",
       "                   (outputscale_prior): GammaPrior()\n",
       "                   (raw_outputscale_constraint): Positive()\n",
       "                 )\n",
       "               )),\n",
       "              ('likelihood',\n",
       "               BernoulliLikelihood(\n",
       "                 (quadrature): GaussHermiteQuadrature1D()\n",
       "               ))]),\n",
       " '_desired_num_outputs': 1}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_X, binary_y = make_classification(\n",
    "            n_samples=10,\n",
    "            n_features=1,\n",
    "            n_redundant=0,\n",
    "            n_informative=1,\n",
    "            random_state=1,\n",
    "            n_clusters_per_class=1,\n",
    "        )\n",
    "binary_X, binary_y = torch.Tensor(binary_X), torch.Tensor(binary_y).reshape(-1, 1)\n",
    "\n",
    "       \n",
    "binary_model = BinaryClassificationGP(\n",
    "    train_X=binary_X, train_Y=binary_y, likelihood=BernoulliLikelihood(), inducing_points=10\n",
    ")\n",
    "\n",
    "vars(binary_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aepsych",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
