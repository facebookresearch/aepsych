{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pairwise_probit import PairwiseGP\n",
    "import torch\n",
    "from variational_gp import BinaryClassificationGP\n",
    "from aepsych.config import Config\n",
    "from gpytorch.likelihoods import BernoulliLikelihood\n",
    "from botorch.models.likelihoods.pairwise import PairwiseProbitLikelihood, PairwiseLikelihood\n",
    "from aepsych.models.base import AEPsychModel\n",
    "from aepsych.models.surrogate import AEPsychSurrogate\n",
    "from aepsych.models.pairwise_probit import PairwiseProbitModel\n",
    "from sklearn.datasets import make_classification\n",
    "from aepsych.utils import promote_0d, _process_bounds\n",
    "from scipy.stats import norm\n",
    "from aepsych.models.utils import select_inducing_points\n",
    "\n",
    "import time, gpytorch, numpy as np\n",
    "from typing import Any, Dict, Optional, Union\n",
    "from aepsych.factory import default_mean_covar_factory\n",
    "from aepsych.config import Config\n",
    "from aepsych.utils_logging import getLogger\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from botorch.models import PairwiseGP, PairwiseLaplaceMarginalLogLikelihood\n",
    "from botorch.models.transforms.input import Normalize\n",
    "\n",
    "\n",
    "import dataclasses\n",
    "import time\n",
    "from typing import Dict, List, Optional\n",
    "from aepsych.utils_logging import getLogger\n",
    "from ax.core.search_space import SearchSpaceDigest\n",
    "from ax.core.types import TCandidateMetadata\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from botorch.utils.datasets import SupervisedDataset\n",
    "from torch import Tensor\n",
    "\n",
    "logger = getLogger()\n",
    "\n",
    "class PairwiseGPModel(PairwiseGP, AEPsychModel, AEPsychSurrogate):\n",
    "    name = \"PairwiseProbitModel\"\n",
    "    outcome_type = \"binary\"\n",
    "    stimuli_per_trial = 1\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        lb: Union[np.ndarray, torch.Tensor],\n",
    "        ub: Union[np.ndarray, torch.Tensor],\n",
    "        dim: Optional[int] = None,\n",
    "        covar_module: Optional[gpytorch.kernels.Kernel] = None,\n",
    "        max_fit_time: Optional[float] = None,\n",
    "    ):\n",
    "        self.lb, self.ub, dim = _process_bounds(lb, ub, dim)\n",
    "\n",
    "        self.max_fit_time = max_fit_time\n",
    "\n",
    "        bounds = torch.stack((self.lb, self.ub))\n",
    "        input_transform = Normalize(d=dim, bounds=bounds)\n",
    "        if covar_module is None:\n",
    "            config = Config(\n",
    "                config_dict={\n",
    "                    \"default_mean_covar_factory\": {\n",
    "                        \"lb\": str(self.lb.tolist()),\n",
    "                        \"ub\": str(self.ub.tolist()),\n",
    "                    }\n",
    "                }\n",
    "            )  # type: ignore\n",
    "            _, covar_module = default_mean_covar_factory(config)\n",
    "        \n",
    "        self.botorch_model_class = None\n",
    "\n",
    "        super().__init__(\n",
    "            datapoints=None,\n",
    "            comparisons=None,\n",
    "            covar_module=covar_module,\n",
    "            jitter=1e-3,\n",
    "            input_transform=input_transform,\n",
    "        )\n",
    "\n",
    "        self.dim = dim  # The Pairwise constructor sets self.dim = None.\n",
    "            \n",
    "\n",
    "    @classmethod\n",
    "    def get_mll_class(cls):\n",
    "        return PairwiseLaplaceMarginalLogLikelihood\n",
    "    \n",
    "    def predict(\n",
    "        self, x, probability_space=False, num_samples=1000, rereference=\"x_min\"\n",
    "    ):\n",
    "        if rereference is not None:\n",
    "            samps = self.sample(x, num_samples, rereference)\n",
    "            fmean, fvar = samps.mean(0).squeeze(), samps.var(0).squeeze()\n",
    "        else:\n",
    "            post = self.posterior(x)\n",
    "            fmean, fvar = post.mean.squeeze(), post.variance.squeeze()\n",
    "\n",
    "        if probability_space:\n",
    "            return (\n",
    "                promote_0d(norm.cdf(fmean)),\n",
    "                promote_0d(norm.cdf(fvar)),\n",
    "            )\n",
    "        else:\n",
    "            return fmean, fvar\n",
    "    \n",
    "    # def fit(\n",
    "    #     self,\n",
    "    #     train_x: torch.Tensor,\n",
    "    #     train_y: torch.Tensor,\n",
    "    #     optimizer_kwargs: Optional[Dict[str, Any]] = None,\n",
    "    #     **kwargs,\n",
    "    # ):\n",
    "    #     self.train()\n",
    "    #     mll = PairwiseLaplaceMarginalLogLikelihood(self.likelihood, self)\n",
    "    #     datapoints, comparisons = PairwiseProbitModel._pairs_to_comparisons(train_x, train_y)\n",
    "    #     self.set_train_data(datapoints, comparisons)\n",
    "\n",
    "    #     optimizer_kwargs = {} if optimizer_kwargs is None else optimizer_kwargs.copy()\n",
    "    #     max_fit_time = kwargs.pop(\"max_fit_time\", self.max_fit_time)\n",
    "    #     if max_fit_time is not None:\n",
    "    #         # figure out how long evaluating a single samp\n",
    "    #         starttime = time.time()\n",
    "    #         _ = mll(self(datapoints), comparisons)\n",
    "    #         single_eval_time = time.time() - starttime\n",
    "    #         n_eval = int(max_fit_time / single_eval_time)\n",
    "    #         optimizer_kwargs[\"maxfun\"] = n_eval\n",
    "    #         logger.info(f\"fit maxfun is {n_eval}\")\n",
    "\n",
    "    #     logger.info(\"Starting fit...\")\n",
    "    #     starttime = time.time()\n",
    "    #     fit_gpytorch_mll(mll, **kwargs, **optimizer_kwargs)\n",
    "    #     logger.info(f\"Fit done, time={time.time()-starttime}\")\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        datasets: List[SupervisedDataset],\n",
    "        metric_names: List[str],\n",
    "        search_space_digest: SearchSpaceDigest,\n",
    "        candidate_metadata: Optional[List[List[TCandidateMetadata]]] = None,\n",
    "        state_dict: Optional[Dict[str, Tensor]] = None,\n",
    "        refit: bool = True,\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        self.train()\n",
    "        self._outcomes = metric_names\n",
    "        if state_dict:\n",
    "            self.model.load_state_dict(state_dict)\n",
    "\n",
    "        if state_dict is None or refit:\n",
    "            mll = self.get_mll_class()(self.likelihood, self)\n",
    "            optimizer_kwargs = {}\n",
    "            if self.max_fit_time is not None:\n",
    "                # figure out how long evaluating a single samp\n",
    "                starttime = time.time()\n",
    "                \n",
    "                if isinstance(self, PairwiseGPModel):\n",
    "                    datapoints, comparisons = PairwiseProbitModel._pairs_to_comparisons(datasets[0].X(), datasets[0].Y().squeeze())\n",
    "                    self.set_train_data(datapoints, comparisons)\n",
    "                    _ = mll(self.model(datapoints), comparisons)\n",
    "                else:\n",
    "                    _ = mll(self.model(datasets[0].X()), datasets[0].Y().squeeze())\n",
    "                single_eval_time = time.time() - starttime\n",
    "                n_eval = int(self.max_fit_time / single_eval_time)\n",
    "                logger.info(f\"fit maxfun is {n_eval}\")\n",
    "                optimizer_kwargs[\"options\"] = {\"maxfun\": n_eval}\n",
    "\n",
    "            logger.info(\"Starting fit...\")\n",
    "            starttime = time.time()\n",
    "            fit_gpytorch_mll(\n",
    "                mll, optimizer_kwargs=optimizer_kwargs\n",
    "            )  # TODO: Support flexible optimizers\n",
    "            logger.info(f\"Fit done, time={time.time()-starttime}\")\n",
    "\n",
    "    @classmethod\n",
    "    def construct_inputs(cls, training_data, **kwargs):\n",
    "        inputs = super().construct_inputs(training_data=training_data, **kwargs)\n",
    "\n",
    "        inducing_size = kwargs.get(\"inducing_size\")\n",
    "        inducing_point_method = kwargs.get(\"inducing_point_method\")\n",
    "        bounds = kwargs.get(\"bounds\")\n",
    "        inducing_points = select_inducing_points(\n",
    "            inducing_size,\n",
    "            inputs[\"covar_module\"],\n",
    "            inputs[\"train_X\"],\n",
    "            bounds,\n",
    "            inducing_point_method,\n",
    "        )\n",
    "\n",
    "        inputs.update(\n",
    "            {\n",
    "                \"inducing_points\": inducing_points,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        return inputs\n",
    "\n",
    "    @classmethod\n",
    "    def get_config_options(cls, config: Config, name: str = None):\n",
    "        options = super().get_config_options(config, name)\n",
    "        classname = cls.__class__.__name__\n",
    "\n",
    "        inducing_point_method = config.get(\n",
    "            classname, \"inducing_point_method\", fallback=\"auto\"\n",
    "        )\n",
    "        inducing_size = config.getint(classname, \"inducing_size\", fallback=10)\n",
    "        learn_inducing_points = config.getboolean(\n",
    "            classname, \"learn_inducing_points\", fallback=False\n",
    "        )\n",
    "\n",
    "        options.update(\n",
    "            {\n",
    "                \"inducing_size\": inducing_size,\n",
    "                \"inducing_point_method\": inducing_point_method,\n",
    "                \"learn_inducing_points\": learn_inducing_points,\n",
    "                \"likelihood\" : PairwiseProbitLikelihood()\n",
    "            }\n",
    "        )\n",
    "\n",
    "        return options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-22 13:36:17,908 [INFO   ] Starting fit...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'PairwiseGPModel'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 29\u001b[0m\n\u001b[0;32m     26\u001b[0m dataset \u001b[39m=\u001b[39m SupervisedDataset(x, y)\n\u001b[0;32m     27\u001b[0m search_space_digest \u001b[39m=\u001b[39m SearchSpaceDigest(lb, ub)\n\u001b[1;32m---> 29\u001b[0m pairwise_model\u001b[39m.\u001b[39;49mfit([dataset], [\u001b[39m\"\u001b[39;49m\u001b[39my\u001b[39;49m\u001b[39m\"\u001b[39;49m], search_space_digest)\n\u001b[0;32m     30\u001b[0m \u001b[39m# vars(pairwise_model)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[1], line 167\u001b[0m, in \u001b[0;36mPairwiseGPModel.fit\u001b[1;34m(self, datasets, metric_names, search_space_digest, candidate_metadata, state_dict, refit, **kwargs)\u001b[0m\n\u001b[0;32m    165\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mStarting fit...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    166\u001b[0m starttime \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m--> 167\u001b[0m fit_gpytorch_mll(\n\u001b[0;32m    168\u001b[0m     mll, optimizer_kwargs\u001b[39m=\u001b[39;49moptimizer_kwargs\n\u001b[0;32m    169\u001b[0m )  \u001b[39m# TODO: Support flexible optimizers\u001b[39;00m\n\u001b[0;32m    170\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFit done, time=\u001b[39m\u001b[39m{\u001b[39;00mtime\u001b[39m.\u001b[39mtime()\u001b[39m-\u001b[39mstarttime\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ckamd\\anaconda3\\envs\\aepsych\\lib\\site-packages\\botorch\\fit.py:105\u001b[0m, in \u001b[0;36mfit_gpytorch_mll\u001b[1;34m(mll, closure, optimizer, closure_kwargs, optimizer_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[39mif\u001b[39;00m optimizer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:  \u001b[39m# defer to per-method defaults\u001b[39;00m\n\u001b[0;32m    103\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39moptimizer\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m optimizer\n\u001b[1;32m--> 105\u001b[0m \u001b[39mreturn\u001b[39;00m FitGPyTorchMLL(\n\u001b[0;32m    106\u001b[0m     mll,\n\u001b[0;32m    107\u001b[0m     \u001b[39mtype\u001b[39m(mll\u001b[39m.\u001b[39mlikelihood),\n\u001b[0;32m    108\u001b[0m     \u001b[39mtype\u001b[39m(mll\u001b[39m.\u001b[39mmodel),\n\u001b[0;32m    109\u001b[0m     closure\u001b[39m=\u001b[39mclosure,\n\u001b[0;32m    110\u001b[0m     closure_kwargs\u001b[39m=\u001b[39mclosure_kwargs,\n\u001b[0;32m    111\u001b[0m     optimizer_kwargs\u001b[39m=\u001b[39moptimizer_kwargs,\n\u001b[0;32m    112\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    113\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\ckamd\\anaconda3\\envs\\aepsych\\lib\\site-packages\\botorch\\utils\\dispatcher.py:93\u001b[0m, in \u001b[0;36mDispatcher.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     91\u001b[0m func \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__getitem__\u001b[39m(types\u001b[39m=\u001b[39mtypes)\n\u001b[0;32m     92\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 93\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     94\u001b[0m \u001b[39mexcept\u001b[39;00m MDNotImplementedError:\n\u001b[0;32m     95\u001b[0m     \u001b[39m# Traverses registered methods in order, yields whenever a match is found\u001b[39;00m\n\u001b[0;32m     96\u001b[0m     funcs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_iter(\u001b[39m*\u001b[39mtypes)\n",
      "File \u001b[1;32mc:\\Users\\ckamd\\anaconda3\\envs\\aepsych\\lib\\site-packages\\botorch\\fit.py:225\u001b[0m, in \u001b[0;36m_fit_fallback\u001b[1;34m(mll, _, __, closure, optimizer, closure_kwargs, optimizer_kwargs, max_attempts, warning_handler, caught_exception_types, **ignore)\u001b[0m\n\u001b[0;32m    222\u001b[0m ckpt: Dict[\u001b[39mstr\u001b[39m, TensorCheckpoint] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m  \u001b[39m# pyre-ignore [9]\u001b[39;00m\n\u001b[0;32m    224\u001b[0m \u001b[39m# Build closure\u001b[39;00m\n\u001b[1;32m--> 225\u001b[0m mll\u001b[39m.\u001b[39;49mtrain()\n\u001b[0;32m    226\u001b[0m \u001b[39mif\u001b[39;00m closure \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    227\u001b[0m     closure \u001b[39m=\u001b[39m get_loss_closure_with_grads(\n\u001b[0;32m    228\u001b[0m         mll, parameters\u001b[39m=\u001b[39mget_parameters(mll, requires_grad\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    229\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\ckamd\\anaconda3\\envs\\aepsych\\lib\\site-packages\\gpytorch\\module.py:299\u001b[0m, in \u001b[0;36mModule.train\u001b[1;34m(self, mode)\u001b[0m\n\u001b[0;32m    297\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m mode) \u001b[39mor\u001b[39;00m mode:\n\u001b[0;32m    298\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_clear_cache()\n\u001b[1;32m--> 299\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mtrain(mode\u001b[39m=\u001b[39;49mmode)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1910\u001b[0m, in \u001b[0;36mModule.train\u001b[1;34m(self, mode)\u001b[0m\n\u001b[0;32m   1908\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mtraining mode is expected to be boolean\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1909\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m mode\n\u001b[1;32m-> 1910\u001b[0m \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m   1911\u001b[0m     module\u001b[39m.\u001b[39mtrain(mode)\n\u001b[0;32m   1912\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1796\u001b[0m, in \u001b[0;36mModule.children\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mchildren\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[\u001b[39m'\u001b[39m\u001b[39mModule\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[0;32m   1791\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Returns an iterator over immediate children modules.\u001b[39;00m\n\u001b[0;32m   1792\u001b[0m \n\u001b[0;32m   1793\u001b[0m \u001b[39m    Yields:\u001b[39;00m\n\u001b[0;32m   1794\u001b[0m \u001b[39m        Module: a child module\u001b[39;00m\n\u001b[0;32m   1795\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1796\u001b[0m     \u001b[39mfor\u001b[39;00m name, module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnamed_children():\n\u001b[0;32m   1797\u001b[0m         \u001b[39myield\u001b[39;00m module\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1816\u001b[0m, in \u001b[0;36mModule.named_children\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1814\u001b[0m memo \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n\u001b[0;32m   1815\u001b[0m \u001b[39mfor\u001b[39;00m name, module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_modules\u001b[39m.\u001b[39mitems():\n\u001b[1;32m-> 1816\u001b[0m     \u001b[39mif\u001b[39;00m module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m module \u001b[39mnot\u001b[39;49;00m \u001b[39min\u001b[39;49;00m memo:\n\u001b[0;32m   1817\u001b[0m         memo\u001b[39m.\u001b[39madd(module)\n\u001b[0;32m   1818\u001b[0m         \u001b[39myield\u001b[39;00m name, module\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'PairwiseGPModel'"
     ]
    }
   ],
   "source": [
    "X, y = make_classification(\n",
    "            n_samples=10,\n",
    "            n_features=1,\n",
    "            n_redundant=0,\n",
    "            n_informative=1,\n",
    "            random_state=1,\n",
    "            n_clusters_per_class=1,\n",
    "        )\n",
    "x, y = torch.Tensor(X), torch.Tensor(y)\n",
    "y = y.reshape(-1, 1)\n",
    "\n",
    "datapoints = torch.Tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "comparisons = torch.Tensor([[0, 1], [2, 1]])\n",
    "\n",
    "seed = 1\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "config_file = \"../../configs/ax_pairwise_opt_example.ini\"\n",
    "config = Config(config_fnames=[config_file])\n",
    "lb = config.getlist(\"common\", \"lb\", element_type=float)\n",
    "ub = config.getlist(\"common\", \"ub\", element_type=float)\n",
    "\n",
    "pairwise_model = PairwiseGPModel(lb, ub)\n",
    "\n",
    "dataset = SupervisedDataset(x, y)\n",
    "search_space_digest = SearchSpaceDigest(lb, ub)\n",
    "\n",
    "pairwise_model.fit([dataset], [\"y\"], search_space_digest)\n",
    "# vars(pairwise_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aepsych",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
