### Example config for active learning (JND estimation) from pairwise obsevations
# The only things that need to be changed for a
# typical experiment are:
# 1. parnames, lb and ub under [common], and optionally target.
# 2. min_asks under init_strat.
# 3. min_asks under opt_strat.

## The common section includes global server parameters and parameters
## reused in multiple other classes
[common]
parnames = [par1, par2] # names of the parameters
lb = [0, 0] # lower bounds of the parameters, in the same order as above
ub = [1, 1] # upper bounds of parameter, in the same order as above
stimuli_per_trial = 2 # the number of stimuli shown in each trial; 1 for single, or 2 for pairwise experiments
outcome_types = [binary] # the type of response given by the participant; can only be [binary] for pairwise for now
strategy_names = [init_strat, opt_strat] # The strategies that will be used, corresponding to the named sections below

# Configuration for the initialization strategy, which we use to gather initial points
# before we start doing model-based acquisition
[init_strat]
min_asks = 10 # number of sobol trials to run
generator = SobolGenerator # The generator class used to generate new parameter values

# Configuration for the optimization strategy, our model-based acquisition
[opt_strat]
min_asks = 20 # number of model-based trials to run

# On every trial, AEPsych can either initialize model hyperparameters randomly and refit
# from scratch, or initialize them to the previous model's parameters. This governs
# how often the former happens vs the latter. Using the previous model's parameters is often faster
# (leading to less waiting between trials) but occasional refitting is useful for avoiding local minima
# in hyperparameters, especially early in the experiment.
refit_every = 5

generator = OptimizeAcqfGenerator # The generator class used to generate new parameter values

# Acquisition function: the objective we use to decide where to sample next. We recommend
# PairwiseMCPosteriorVariance for global exploration, and qLogNoisyExpectedImprovement for
# optimization. For other options, check out the botorch and aepsych docs, though note
# that in the pairwise setting not all acquisition functions will make sense
acqf = qLogNoisyExpectedImprovement

# The model, which must conform to the stimuli_per_trial and outcome_types settings above.
# Use GPClassificationModel or GPRegressionModel for single or PairwiseProbitModel for pairwise.
model = PairwiseProbitModel

## Below this section are configurations of all the classes defined in the section above,
## matching the API in the code.

## Acquisition function settings; we recommend not changing this.
[PairwiseMCPosteriorVariance]
# The transformation of the latent function before threshold estimation. ProbitObjective
# lets us search where the probability is uncertain (vs where there is high variance
# in the function itself, which might still lead to low variance on the probability
# after the probit transform).
objective = ProbitObjective

## This configures the PairwiseGP model
[PairwiseProbitModel]
# Number of inducing points for approximate inference. 100 is fine for 2d and overkill for 1d;
# for larger dimensions, scale this up.
inducing_size = 100

# A "factory" function (defined in aepsych) that builds the GP mean and covariance. The other
# applicable option is song_mean_covar_factory (for the linear-additive model of some
# previous work).
mean_covar_factory = default_mean_covar_factory

## Generator settings, governing acquisition function optimization.
[OptimizeAcqfGenerator]
restarts = 10 # number of restarts for acquisition function optimization.
samps = 1000 # number of samples for quasi-random initialization of the acquisition function optimizer

## Acquisition function settings; we recommend not changing this.
[qLogNoisyExpectedImprovement]
objective = ProbitObjective # The transformation of the latent function before threshold estimation.
